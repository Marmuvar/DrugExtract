{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191aca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Author Mark Benmuvhar\n",
    "# pdf_read_patent\n",
    "# Version 2.0.0\n",
    "# 10/16/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da227898",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pip install tabula-py\n",
    "#pip install PyPDF2\n",
    "import tabula\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43944beb",
   "metadata": {},
   "source": [
    "**Other references**\n",
    "Zhu, Aaron. (2022, Match 10).  Extract PDF text while preserving whitespace using python and pytesseract.  *Towards Data Science.*  https://towardsdatascience.com/pdf-text-extraction-while-preserving-whitespace-using-python-and-pytesseract-ec142743e805  \n",
    "\n",
    "**API references:**\n",
    "https://tabula-py.readthedocs.io/en/latest/tabula.html  \n",
    "\n",
    "\n",
    "**Required supporting files**  \n",
    "\n",
    "https://tesseract-ocr.github.io/tessdoc/Downloads.html  \n",
    "\n",
    "https://github.com/tesseract-ocr/tessdoc  \n",
    "\n",
    "https://github.com/oschwartz10612/poppler-windows/releases?page=1  \n",
    "\n",
    "**Programming References**  \n",
    "\n",
    "https://thewebdev.info/2022/04/17/how-to-fix-appending-turns-my-list-to-nonetype-with-python/#:~:text=To%20fix%20appending%20turns%20my%20list%20to%20NoneType,%5B%27a%27%2C%20%27b%27%2C%20%27c%27%2C%20%27d%27%5D%20a_list%20%3D%20a_list.append%20%28%27e%27%29  \n",
    "\n",
    "https://stackoverflow.com/questions/65822875/referencing-the-last-page-in-a-pdf-with-tabula\n",
    "\n",
    "https://www.geeksforgeeks.org/how-to-iterate-over-files-in-directory-using-python/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a20a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upversion to v2_0 for Rough Draft Submission, 10/16/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d814b52c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# In v1_4 from v1_3_4\n",
    "# added default start page to allow modifications due to odd parsing of graphs in OB29\n",
    "def input_pdf(pdf_doc, area, col, pd_opts, pages=[], start = 27):\n",
    "    \n",
    "    if type(pages) == int:\n",
    "        read_pages = pages\n",
    "    elif len(pages) == 0:\n",
    "        fh=open(pdf_doc, mode='rb')\n",
    "        reader = PyPDF2.PdfFileReader(fh)\n",
    "        read_pages = list(range(start, reader.getNumPages()))\n",
    "        fh.close()\n",
    "    else:\n",
    "        read_pages = str(pages[0])+'-'+str(pages[1])\n",
    "    \n",
    "    return (\n",
    "        tabula.read_pdf(\n",
    "            input_path = pdf_doc,\n",
    "            output_format = 'dataframe',\n",
    "            pages = read_pages,\n",
    "            guess = False,\n",
    "            area = area,\n",
    "            relative_area = True,\n",
    "            stream = True,\n",
    "            columns = col,\n",
    "            pandas_options = pd_opts\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a42da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sections(X, opts = None):\n",
    "\n",
    "# added options to skip drug product sections\n",
    "    \n",
    "# page starts and end for df\n",
    "    book = None\n",
    "    drug_pg = None\n",
    "    otc_pg = None\n",
    "    patent_pg = None\n",
    "    terms_pg = None\n",
    "\n",
    "# Set search strings based on section headers or page numbers\n",
    "    p2 = re.compile(r'3.*1.*of.*\\d\\d\\d')\n",
    "    p3 = re.compile(r'OTC DRUG PRODUCT LIST')\n",
    "    p4 = re.compile(r'PRESCRIPTION AND OTC DRUG PRODUCT')\n",
    "    p5 = re.compile(r'EXCLUSIVITY TERMS')\n",
    "    \n",
    "\n",
    "    for j in range(0, len(X)):\n",
    "        if pd.notna(X.iloc[j,1]):\n",
    "            if ((drug_pg == None) & (opts == None)):\n",
    "                m2 = p2.search(X.iloc[j,1])\n",
    "                if m2:\n",
    "                    drug_pg = j\n",
    "            elif ((otc_pg == None) & (opts == None)):\n",
    "                m3 = p3.search(X.iloc[j,1])\n",
    "                if m3:\n",
    "                    otc_pg = j\n",
    "            elif  (patent_pg == None):\n",
    "                m4 = p4.search(X.iloc[j,1])\n",
    "                if m4:\n",
    "                    patent_pg = j\n",
    "            elif (terms_pg == None):\n",
    "                m5 = p5.search(X.iloc[j,1])\n",
    "                if m5:\n",
    "                    terms_pg = j\n",
    "                    return drug_pg, otc_pg, patent_pg, terms_pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##functions for drug product module\n",
    "def get_col(X, n):\n",
    "# Returns combined string from values starting in column n\n",
    "# Applys to drug substance and drug product name\n",
    "    col=str()\n",
    "    for i in range(n,len(X)):\n",
    "        if type(X)!= list:\n",
    "            if pd.notna(X.iloc[i]):\n",
    "                col=col+X.iloc[i]\n",
    "        else:\n",
    "            if pd.notna(X[i]):\n",
    "                col=col+X[i]\n",
    "    return(col)\n",
    "\n",
    "# parse_page() looks for stray page header information\n",
    "def parse_page(X, mode = 0):\n",
    "    if re.search(r'Footnote:',X):\n",
    "        return('footer')\n",
    "    if mode == 1:\n",
    "        return(re.search(\n",
    "            r'PATENT|REQUESTED|CODES|APPROVED|PRESCRIPTION|EXPIRATION|'\n",
    "            r'report|3.*\\d*.*of.*\\d\\d\\d|ADA\\.*\\d*.*of.*\\d\\d\\d',\n",
    "            X) == None\n",
    "              )\n",
    "    else:\n",
    "        return(re.search(\n",
    "            r'PATENT|REQUESTED|CODES|APPROVED|PRESCRIPTION|EXPIRATION|report', \n",
    "            X)==None\n",
    "              )\n",
    "    \n",
    "def chk_ml_head(X, i):\n",
    "    return pd.notna([X.iloc[i,0],\n",
    "                     X.iloc[i + 1,0]]\n",
    "                   ).all()\n",
    "\n",
    "# chk_ml_body() determines if line is part of multi-line entry\n",
    "# For this, col should be present and oth should be empty\n",
    "# Otherwise the next line is either a general body line or a header.  \n",
    "\n",
    "def chk_ml_body(X, i, col, oth):\n",
    "    if i < len(X):\n",
    "        a = pd.isna(X.loc[i, oth]).all()\n",
    "        b = pd.notna(X.loc[i, col]).any()\n",
    "        Z = a & b\n",
    "\n",
    "    else:\n",
    "        Z = False\n",
    "    return Z\n",
    "\n",
    "\n",
    "def chk_nda_fmt(s):\n",
    "    if type(s) == str:\n",
    "        return re.match(r'\\w\\d\\d\\d\\d',s)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# parse_header() splits drug substance and drug product information\n",
    "# in the patent module\n",
    "def parse_header(X, mode):\n",
    "    \n",
    "    #headers for 25th to 29 edition\n",
    "    if mode == 1:\n",
    "        m3 = re.split(r';', X)\n",
    "        \n",
    "    #headers for editions from 30 onwards\n",
    "    else:            \n",
    "        m3 = re.split((r'\\s-\\s|-\\s|\\s-(?!\\Z)|-(?!\\Z)'),X,1)\n",
    "\n",
    "    return(get_col(m3[:-1],0), m3[-1])             \n",
    "\n",
    "# parse_body returns a row of data frame body information\n",
    "# Used for appending body text information onto row information\n",
    "def parse_body(X, row, col):\n",
    "    return X[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a7f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated in V1_5_1\n",
    "# Format parsed by column was creating incorrect values due to parsed literal \"NA\" text.\n",
    "# This was leading to incomplete headers and string values in integer columns.  \n",
    "\n",
    "def parse_pats(df, tf, start, end, mode=1):\n",
    "    \n",
    "# input is a list of dataframes. \n",
    "#X is the columnar format\n",
    "#T is row-wise format.  \n",
    "    X = df[0]\n",
    "    T = tf[0]\n",
    "    \n",
    "    \n",
    "    pats=pd.DataFrame(\n",
    "        {\n",
    "            'DS_Name':[''],\n",
    "            'DP_Name':[''],\n",
    "            'Application_No':[''],\n",
    "            'Product_No':[''],\n",
    "            'Patent_No':[''],\n",
    "            'Patent_Expiration_Date':[''],\n",
    "            'Patent_Codes':[''],\n",
    "            'Patent_Delist':[''],\n",
    "            'Exclusivity':[''],\n",
    "            'Exclusive_Expire':['']  \n",
    "        }\n",
    "    )\n",
    "    \n",
    "    #temporary value holders\n",
    "    DS_Name = None\n",
    "    DP_Name = None\n",
    "    head_line = str()\n",
    "    otpt_row = pats.copy()\n",
    "    \n",
    "    #sequence flags\n",
    "    flag_ml = False\n",
    "      \n",
    "    for i in range(start, end):\n",
    "        ipt_line = get_col(X.iloc[i, : ],0)\n",
    "        if parse_page(ipt_line, mode) == True:\n",
    "\n",
    "# Process drug sub / route / product header information\n",
    "            if pd.notna(X.iloc[i, 0]):\n",
    "                head_line = head_line + get_col(T.iloc[i, : ],0)\n",
    "                if not chk_ml_head(X, i):\n",
    "                    DS_Name, DP_Name = parse_header(head_line, mode)\n",
    "                    otpt_row.iloc[0, 0 : 2] = [DS_Name, DP_Name]\n",
    "                    head_line = ''\n",
    "                    \n",
    "# Process body information\n",
    "            else:\n",
    "                ipt_line2 = X.iloc[i,:]\n",
    "                #V1_5.  9/20/22\n",
    "                #do direct link for name rather than use parse_body function.  \n",
    "                if pd.notna(X.iloc[i,1]):\n",
    "                    otpt_row.iloc[0, 2: ] = (\n",
    "                        ipt_line2[~ipt_line2.index.isin(['DP_Name'])].copy()\n",
    "                    )\n",
    "                else:\n",
    "                    otpt_row.iloc[0, 4: ] = (\n",
    "                        ipt_line2[~ipt_line2.index.isin(['DP_Name',\n",
    "                                                         'Application_No', \n",
    "                                                         'Product_No'])].copy())\n",
    "                if pats.iloc[0,0] != '':\n",
    "                    pats = pd.concat([pats, otpt_row])\n",
    "                else:\n",
    "                    pats = otpt_row.copy()\n",
    "                head_line = ''\n",
    "                \n",
    "        #conditional to catch footer sections.  Currently Unused.        \n",
    "        elif parse_page(ipt_line,1) == 'footer':\n",
    "            return(pats)\n",
    "            break\n",
    "        else:\n",
    "            head_line = ''          \n",
    "    return(pats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccad618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_pats():\n",
    "#Updated in V1_5_1\n",
    "# Added dataframe parsed by row as secondary reference for drug name headers\n",
    "# Updated start page numbers for initial OB parsing.  \n",
    "    \n",
    "# pdf_io\n",
    "    directory = ('OrangeBook\\Testing')\n",
    "    otpt_directory = ('OrangeBook\\Testing\\csv\\\\')\n",
    "    \n",
    "#for page scans\n",
    "    pg_col = [10]\n",
    "    pg_area = [0, 5,95,95]\n",
    "    pg_pd_opt = {\n",
    "            'header':0,\n",
    "            'index_col':False,\n",
    "            'names':[\n",
    "                    'Header_Txt',\n",
    "                    'other'\n",
    "                ]\n",
    "            }\n",
    "    # for Patents\n",
    "    pats_pg_area = [0, 5,95,95]\n",
    "\n",
    "# OB25 to 28;  Note that Delist is absent\n",
    "    pats_col_25 = [49,85,100,200,290,385,386,460]                   \n",
    "    pats_col_26 = [65,100,125,220,295,385,386,485]\n",
    "    pats_col_bf29 = [65,100,125,200,290,380,381,470]\n",
    "    pats_col_29 = [67,100,125,200,290,380,381,470]\n",
    "    #Edit 8/10/22 for OB30\n",
    "    pats_col_bf31 = [62,105,130,200,280,355,400,475]\n",
    "    pats_col_bf34 = [65,110,130,200,280,355,400,475]                \n",
    "    pats_col_fr34 = [54,100,125,200,280,350,400,460]\n",
    "    pats_col_fr38 = [54,100,125,200,280,350,400,475]\n",
    "    \n",
    "    pats_pd_opt = {\n",
    "        'header':0,\n",
    "        'index_col':False,\n",
    "        'names':[\n",
    "            'DP_Name',\n",
    "            'Application_No',\n",
    "            'Product_No',\n",
    "            'Patent_No',\n",
    "            'Patent_Expiration_Date',\n",
    "            'Patent_Codes',\n",
    "            'Patent_Delist',\n",
    "            'Exclusivity',\n",
    "            'Exclusive_Expire'\n",
    "        ]\n",
    "    } \n",
    "    \n",
    "    # file naming variables\n",
    "    p = re.compile(r'.pdf')\n",
    "    p2 = re.compile(r'\\\\')\n",
    "    p_ed = re.compile(r'\\d\\d(?=\\D\\D)')\n",
    "       \n",
    "    for filename in os.scandir(directory):\n",
    "        if not filename.is_dir():\n",
    "            try:\n",
    "                print(filename)\n",
    "                if int(p_ed.search(filename.name)[0]) in [25,29]:\n",
    "                    tf = input_pdf(filename.path, pg_area, pg_col, pg_pd_opt, start = 871)\n",
    "                elif int(p_ed.search(filename.name)[0]) in [26]:\n",
    "                    tf = input_pdf(filename.path, pg_area, pg_col, pg_pd_opt, start = 854)\n",
    "                else:\n",
    "                    tf = input_pdf(filename.path, pg_area, pg_col, pg_pd_opt, start = 871)\n",
    "                print('in main, looking for pages in : ',filename.path)\n",
    "                drug_pg, otc_pg, patent_pg, terms_pg = find_sections(tf[0] , opts = 1)\n",
    "                print ('Drug List between Pages: {} and {} \\n\\\n",
    "                        Patent List between Pages: {} and {}'\\\n",
    "                        .format(drug_pg, otc_pg, patent_pg, terms_pg)\n",
    "                 )\n",
    "                \n",
    "            except Exception as e:\n",
    "                print('File Input error in ',filename, '\\n',e)\n",
    "                \n",
    "                # Patent and Exclusivity Parsing Block\n",
    "        #try:\n",
    "            print('Patent Block')\n",
    "            print('Filename is',filename.name)\n",
    "            if int(p_ed.search(filename.name)[0]) == 26:\n",
    "                df = input_pdf(filename.path, pats_pg_area, pats_col_26, \n",
    "                               pats_pd_opt, start = 854)\n",
    "                mode = 1\n",
    "            elif int(p_ed.search(filename.name)[0]) == 25:\n",
    "                df = input_pdf(filename.path, pats_pg_area, pats_col_25, \n",
    "                               pats_pd_opt , start = 871)\n",
    "                mode = 1  \n",
    "            elif int(p_ed.search(filename.name)[0]) < 29:\n",
    "                df = input_pdf(filename.path, pats_pg_area, pats_col_bf29, \n",
    "                               pats_pd_opt, start = 871)\n",
    "                mode = 1\n",
    "            elif int(p_ed.search(filename.name)[0]) == 29:\n",
    "                df = input_pdf(filename.path, pats_pg_area, pats_col_29, \n",
    "                               pats_pd_opt, start = 871)\n",
    "                mode = 1\n",
    "            elif int(p_ed.search(filename.name)[0]) < 31:\n",
    "                df = input_pdf(filename.path, pats_pg_area, pats_col_bf31, \n",
    "                               pats_pd_opt, start = 871)\n",
    "                if int(p_ed.search(filename.name)[0]) == 29:\n",
    "                    mode = 1 \n",
    "                else:\n",
    "                    mode = 0    \n",
    "            elif int(p_ed.search(filename.name)[0])<34:\n",
    "                df = input_pdf(filename.path, pats_pg_area, pats_col_bf34, \n",
    "                               pats_pd_opt, start = 871)\n",
    "                mode = 0\n",
    "            elif int(p_ed.search(filename.name)[0])<38:\n",
    "                df = input_pdf(filename.path, pats_pg_area, pats_col_fr34, \n",
    "                               pats_pd_opt, start = 871)\n",
    "                mode = 0\n",
    "            else:\n",
    "                df=input_pdf(filename.path, pats_pg_area, pats_col_fr38, \n",
    "                             pats_pd_opt, start = 871) \n",
    "                mode = 0\n",
    "                \n",
    "            pats = parse_pats(df, tf, patent_pg, terms_pg, mode)\n",
    "            rn_out_doc = p.sub('_pat_2_0.csv', filename.name)\n",
    "            rn_out_doc = otpt_directory + rn_out_doc\n",
    "            pats.to_csv(rn_out_doc)\n",
    "            print('Completed parsing drug patent info from ', filename.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c159efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
