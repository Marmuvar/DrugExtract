{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e5f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Author Mark Benmuvhar\n",
    "# pdf_read_patent\n",
    "# Version 2.0.0\n",
    "# 10/16/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191aca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tabula-py\n",
    "#pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da227898",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tabula\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43944beb",
   "metadata": {},
   "source": [
    "**Other references**\n",
    "Zhu, Aaron. (2022, Match 10).  Extract PDF text while preserving whitespace using python and pytesseract.  *Towards Data Science.*  https://towardsdatascience.com/pdf-text-extraction-while-preserving-whitespace-using-python-and-pytesseract-ec142743e805  \n",
    "\n",
    "**API references:**\n",
    "https://tabula-py.readthedocs.io/en/latest/tabula.html  \n",
    "\n",
    "\n",
    "**Required supporting files**  \n",
    "\n",
    "https://tesseract-ocr.github.io/tessdoc/Downloads.html  \n",
    "\n",
    "https://github.com/tesseract-ocr/tessdoc  \n",
    "\n",
    "https://github.com/oschwartz10612/poppler-windows/releases?page=1  \n",
    "\n",
    "**Programming References**  \n",
    "\n",
    "https://thewebdev.info/2022/04/17/how-to-fix-appending-turns-my-list-to-nonetype-with-python/#:~:text=To%20fix%20appending%20turns%20my%20list%20to%20NoneType,%5B%27a%27%2C%20%27b%27%2C%20%27c%27%2C%20%27d%27%5D%20a_list%20%3D%20a_list.append%20%28%27e%27%29  \n",
    "\n",
    "https://stackoverflow.com/questions/65822875/referencing-the-last-page-in-a-pdf-with-tabula\n",
    "\n",
    "https://www.geeksforgeeks.org/how-to-iterate-over-files-in-directory-using-python/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d814b52c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# In v1_4 from v1_3_4\n",
    "# added default start page to allow modifications due to odd parsing of graphs in OB29\n",
    "def input_pdf(pdf_doc, area, col, pd_opts, pages=[], start = 27):\n",
    "    \n",
    "    if type(pages) == int:\n",
    "        read_pages = pages\n",
    "    elif len(pages) == 0:\n",
    "        fh=open(pdf_doc, mode='rb')\n",
    "        reader = PyPDF2.PdfFileReader(fh)\n",
    "        read_pages = list(range(start, reader.getNumPages()))\n",
    "        fh.close()\n",
    "    else:\n",
    "        read_pages = str(pages[0])+'-'+str(pages[1])\n",
    "    \n",
    "    return (\n",
    "        tabula.read_pdf(\n",
    "            input_path = pdf_doc,\n",
    "            output_format = 'dataframe',\n",
    "            pages = read_pages,\n",
    "            guess = False,\n",
    "            area = area,\n",
    "            relative_area = True,\n",
    "            stream = True,\n",
    "            columns = col,\n",
    "            pandas_options = pd_opts\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a42da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated from pdf_read_fnl_v1_4 to catch multiple sections \n",
    "# discnt_v0_3 added options to skip drug product sections (fnl_v_1_5_1)\n",
    "def find_dcn_sections(X, opts = None):\n",
    "    \n",
    "# page starts and end for df\n",
    "    book = None\n",
    "    drug_pg = None\n",
    "    otc_pg = None\n",
    "    dcn_pg = None\n",
    "    ode_pg = None\n",
    "    patent_pg = None\n",
    "    terms_pg = None\n",
    "\n",
    "# Set search strings based on section headers or page numbers\n",
    "    p2 = re.compile(r'3.*1.*of.*\\d\\d\\d')\n",
    "    p3 = re.compile(r'OTC DRUG PRODUCT LIST')\n",
    "    p4 = re.compile(r'DISCONTINUED DRUG PRODUCT LIST')\n",
    "    p5 = re.compile(r'DESIGNATIONS AND')\n",
    "    p6 = re.compile(r'PRESCRIPTION AND OTC DRUG PRODUCT')\n",
    "    p7 = re.compile(r'EXCLUSIVITY TERMS')\n",
    "    \n",
    "\n",
    "    for j in range(0, len(X)):\n",
    "        if pd.notna(X.iloc[j,1]):\n",
    "            if ((drug_pg == None) & (opts == None)):\n",
    "                m2 = p2.search(X.iloc[j,1])\n",
    "                if m2:\n",
    "                    drug_pg = j\n",
    "            elif ((otc_pg == None) & (opts == None)):\n",
    "                m3 = p3.search(X.iloc[j,1])\n",
    "                if m3:\n",
    "                    otc_pg = j\n",
    "            elif dcn_pg == None:\n",
    "                m4 = p4.search(X.iloc[j,1])\n",
    "                if m4:\n",
    "                    dcn_pg = j\n",
    "            elif ode_pg == None:\n",
    "                m5 = p5.search(X.iloc[j,1])\n",
    "                if m5:\n",
    "                    ode_pg = j  \n",
    "                    return drug_pg, otc_pg, dcn_pg, ode_pg, patent_pg, terms_pg\n",
    "            elif  (patent_pg == None) & (opts == None):\n",
    "                m6 = p6.search(X.iloc[j,1])\n",
    "                if m6:\n",
    "                    patent_pg = j\n",
    "            elif (terms_pg == None) & (opts == None):\n",
    "                m7 = p7.search(X.iloc[j,1])\n",
    "                if m7:\n",
    "                    terms_pg = j\n",
    "                    return drug_pg, otc_pg, dcn_pg, ode_pg, patent_pg, terms_pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##functions for drug product module\n",
    "# Function get_col()\n",
    "# Returns combined string from values starting in column n\n",
    "# Applys to drug substance and drug product name\n",
    "\n",
    "def get_col(X, n):\n",
    "    col=str()\n",
    "    for i in range(n,len(X)):\n",
    "        if type(X)!= list:\n",
    "            if pd.notna(X.iloc[i]):\n",
    "                col=col+X.iloc[i]\n",
    "        else:\n",
    "            if pd.notna(X[i]):\n",
    "                col=col+X[i]\n",
    "    return(col)\n",
    "\n",
    "# parse_page() looks for stray page header information\n",
    "def parse_page(X, mode=0):\n",
    "    if re.search(r'Footnote:',X):\n",
    "        return('footer')\n",
    "    if mode == 1:\n",
    "        return(re.search(r'PATENT|REQUESTED|CODES|APPROVED|PRESCRIPTION|'\n",
    "                         r'EXPIRATION|report|3.*\\d*.*of.*\\d\\d\\d', X)==None)\n",
    "    else:\n",
    "        return(re.search(r'PATENT|REQUESTED|CODES|APPROVED|PRESCRIPTION|'\n",
    "                         r'EXPIRATION|report', X)==None)\n",
    "    \n",
    "def chk_ml_head(X,i):\n",
    "    return pd.notna([X.iloc[i,0],\n",
    "                     X.iloc[i+1,0]]\n",
    "                   ).all()\n",
    "\n",
    "# chk_ml_body() determines if line is part of multi-line entry\n",
    "# For this, col should be present and oth should be empty\n",
    "# Otherwise the next line is either a general body line or a header.  \n",
    "\n",
    "def chk_ml_body(X,i,col, oth):\n",
    "    if i < len(X):\n",
    "        a = pd.isna(X.loc[i, oth]).all()\n",
    "        b = pd.notna(X.loc[i,col]).any()\n",
    "        Z = a & b\n",
    "\n",
    "    else:\n",
    "        Z = False\n",
    "    return Z\n",
    "\n",
    "\n",
    "def chk_nda_fmt(s):\n",
    "    if type(s) == str:\n",
    "        return re.match(r'\\w\\d\\d\\d\\d',s)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# parse_header() splits drug substance and drug product information\n",
    "# in the patent module\n",
    "def parse_header(X, mode):\n",
    "    \n",
    "    #headers for 25th to 29 edition\n",
    "    if mode == 1:\n",
    "        m3 = re.split(r';', X)\n",
    "        \n",
    "    #headers for editions from 30 onwards\n",
    "    else:            \n",
    "        m3 = re.split((r'\\s-\\s|-\\s|\\s-(?!\\Z)|-(?!\\Z)'),X,1)\n",
    "\n",
    "    return(get_col(m3[:-1],0), m3[-1])             \n",
    "\n",
    "# parse_body returns a row of data frame body information\n",
    "# Used for appending body text information onto row information\n",
    "def parse_body(X, row, col):\n",
    "    return X[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f6709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discontinued Drug Product Module\n",
    "# Modified from Drug Product Module v 1_4 by removing checks for BE presence in entry bodies\n",
    "\n",
    "def parse_dcn(df, tf, start, end, dpn_pos, note_pos, mode):\n",
    "    \n",
    "    X = df[0]\n",
    "    T = tf[0]\n",
    "    \n",
    "    prods=pd.DataFrame(data={\n",
    "                        'ds_name' : [''],\n",
    "                        'route' : [''], \n",
    "                        'dp_name': [''],\n",
    "                        'be' : [''],\n",
    "                        'note' : [''],\n",
    "                        'sponsor' : [''],\n",
    "                        'strength' : [''],\n",
    "                        'app_no' : [''],\n",
    "                        'prod_no' : [''],\n",
    "                        'app_date' : ['']  \n",
    "                    }\n",
    "                )\n",
    "    \n",
    "    #temporary value holders\n",
    "    DS_Name = None\n",
    "    DP_Name = None\n",
    "    head_line = ''\n",
    "    otpt_row = prods.copy()\n",
    "    prev_head = otpt_row.iloc[0, 0:3].copy()\n",
    "    old_sponsor = ''\n",
    "    \n",
    "    fl_first_entry = True\n",
    "    fl_read_head = True\n",
    "    fl_proc_body = False\n",
    "    fl_ml_body = False\n",
    "    fl_rpt_sponsor = False\n",
    "    \n",
    "    for i in range(start,end):\n",
    "        ipt_line = X.iloc[i, : ]\n",
    "        #print('ipt_line:',ipt_line)\n",
    "        #print('Text_line:',T.iloc[i,:])\n",
    "              \n",
    "        if fl_proc_body:\n",
    "            if fl_first_entry == True:\n",
    "                prods.iloc[0, :] = otpt_row\n",
    "                fl_proc_body = False\n",
    "                fl_first_entry = False\n",
    "            else:\n",
    "                prods = pd.concat([prods, otpt_row])\n",
    "                fl_proc_body = False\n",
    "                head_line = ''\n",
    "                           \n",
    "        if parse_page(get_col(ipt_line, 0) ,mode) == True:\n",
    "                        \n",
    "# process header information\n",
    "# Any time we get to header after first iteration, the body information should process\n",
    "# Start with the lowest level header and work upwards\n",
    "# Is it a drug product name, route, or drug substance\n",
    "# Only drug substance can be multi-line\n",
    "# Clear head_line information after updating\n",
    "\n",
    "            if (chk_nda_fmt(X.loc[i, 'app_no'])==None) & (fl_ml_body==False):\n",
    "                if pd.isna(X.loc[i, ['be', 'route']]).all():\n",
    "                    otpt_row.loc[0 ,'dp_name'] = get_col(T.iloc[i, : ],1)\n",
    "                    head_line = ''\n",
    "                    if (prev_head != otpt_row.iloc[0, 0:3]).all():\n",
    "                        fl_rpt_sponsor = False\n",
    "                elif pd.isna(X.loc[i, 'be']):\n",
    "                    otpt_row.loc[0, 'route'] = get_col(T.iloc[i, : ],1)\n",
    "                    head_line = ''\n",
    "                else:\n",
    "                    if not chk_ml_head(X,i):\n",
    "                        head_line = head_line + ' '+ get_col(T.iloc[i, :],1)\n",
    "                        otpt_row.loc[0, 'ds_name'] = head_line\n",
    "                        head_line = ''\n",
    "                    else:\n",
    "                        head_line = head_line + ' ' + get_col(T.iloc[i, :],1)\n",
    "\n",
    "# process body information\n",
    "# Start from bottom case and work up\n",
    "# Start from far right case and work left\n",
    "\n",
    "# Is row part of a multi-line entry?\n",
    "# Is it a multi-line strength and multi-line sponsor?\n",
    "# Is it a multi-line strength?\n",
    "# Is it a multi-line sponsor?\n",
    "# Is the line part of a block of sponsor information?\n",
    "# Is it the initial body entry with expected content? \n",
    "\n",
    "            #Single columns to append and write\n",
    "\n",
    "            elif pd.notna(X.loc[i, ['strength','sponsor']]).any() &\\\n",
    "                    (pd.isna(X.loc[i, ~X.columns.isin(['strength', 'sponsor'])]).all()):\n",
    "                if pd.notna(X.loc[i, 'strength']):\n",
    "                    #Possible to have literal 'N/A in text, so convert to string'\n",
    "                    otpt_row.loc[0, 'strength'] = (\n",
    "                        str(otpt_row.loc[0, 'strength']) + ' '+ str(X.loc[i, 'strength']))\n",
    "                if pd.notna(X.loc[i, 'sponsor']):\n",
    "                    otpt_row.loc[0, 'sponsor'] = (\n",
    "                        otpt_row.loc[0, 'sponsor'] + ' ' + str(X.loc[i, 'sponsor']))\n",
    "                if chk_ml_body(X, i+1, ['sponsor','strength'], \n",
    "                               ['dp_name','route','app_no']):\n",
    "                    fl_proc_body = False\n",
    "                    fl_ml_body = True\n",
    "                else:\n",
    "                    fl_proc_body = True\n",
    "                    fl_ml_body = False\n",
    "                    \n",
    "            #Whole entries with or without repeated sponsor names\n",
    "            else:\n",
    "                old_sponsor = str(otpt_row.loc[0, 'sponsor'])\n",
    "                old_strength = str(otpt_row.loc[0,'strength'])\n",
    "                otpt_row.loc[0, ~otpt_row.columns.isin(['ds_name', 'route', 'dp_name'])] = \\\n",
    "                             X.loc[i, ~X.columns.isin(['dp_name', 'route'])]\n",
    "                if chk_ml_body(X, i+1, ['sponsor','strength'], \n",
    "                               ['route','note','dp_name', 'app_no','app_date']):\n",
    "                    fl_proc_body = False\n",
    "                    fl_ml_body = True                  \n",
    "                    if pd.isna(X.loc[i,'sponsor']):\n",
    "                        otpt_row.loc[0, 'sponsor'] = old_sponsor\n",
    "                \n",
    "                #Alternately, add an analogous section for strength.  \n",
    "                elif pd.isna(X.loc[i,'sponsor']):\n",
    "                    otpt_row.loc[0, 'sponsor'] = old_sponsor\n",
    "                    fl_proc_body = True\n",
    "                    fl_ml_body = False\n",
    "                else:\n",
    "                    prev_head = otpt_row.loc[0, ['ds_name', 'route', 'dp_name']]\n",
    "                    fl_proc_body = True\n",
    "                    fl_ml_body = False\n",
    "        else:\n",
    "            fl_ml_body = False\n",
    "    return(prods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d51ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated in v1_4 from v1_3_4\n",
    "# pass initial parsed table (line-by-line rendering) to parse_prods \n",
    "# in addition to column-wise parse\n",
    "# Use a defined start page for input_pdf due to odd handling of arrow graphics \n",
    "# in volume 25 and 29.\n",
    "\n",
    "def main_dcn():\n",
    "    \n",
    "# pdf_io\n",
    "    directory = ('OrangeBook\\Testing')\n",
    "    otpt_directory = ('OrangeBook\\Testing\\csv\\\\')\n",
    "    \n",
    "# file naming variables\n",
    "    p = re.compile(r'.pdf')\n",
    "    p_ed = re.compile(r'\\d\\d(?=\\D\\D)')\n",
    "    p_yr = re.compile(r'\\d\\d\\d\\d')\n",
    "    \n",
    "#for page scans\n",
    "    pg_col = [10]\n",
    "    pg_area = [0, 5,99,95]\n",
    "    pg_pd_opt = {\n",
    "            'header':0,\n",
    "            'index_col':False,\n",
    "            'names':[\n",
    "                    'Header_Txt',\n",
    "                    'other'\n",
    "                ]\n",
    "            } \n",
    "\n",
    "    # For drug product\n",
    "    #col_25 modified from read_fnl_v1_4\n",
    "    dp_col_25 = [85,90,94,98,205,395,435,475]      \n",
    "    dp_col_bf34 = [88,90,97,100,205,400,450,475]  \n",
    "    dp_col_fr34 = [62,77,82,100,210,400,450,475]\n",
    "    dp_pg_area = [0, 5,99,95]\n",
    "    dp_pd_opt_bf34 = {\n",
    "            'header':0,\n",
    "            'index_col':False,\n",
    "            'names':[\n",
    "                'be',\n",
    "                'route',\n",
    "                'note',\n",
    "                'dp_name',\n",
    "                'sponsor',\n",
    "                'strength',\n",
    "                'app_no', \n",
    "                'prod_no',\n",
    "                'app_date'\n",
    "                ]\n",
    "            }\n",
    "\n",
    "    dp_pd_opt_fr34 = {\n",
    "            'header':0,\n",
    "            'index_col':False,\n",
    "            'names':[\n",
    "                'be',\n",
    "                'route',\n",
    "                'dp_name',\n",
    "                'note',\n",
    "                'sponsor',\n",
    "                'strength',\n",
    "                'app_no', \n",
    "                'prod_no',\n",
    "                'app_date'\n",
    "                ]\n",
    "            } \n",
    "\n",
    "    for filename in os.scandir(directory):\n",
    "        if not filename.is_dir():\n",
    "            try:\n",
    "                print(filename)\n",
    "                if int(p_ed.search(filename.name)[0]) in [25, 29]:\n",
    "                    tf=input_pdf(filename.path, pg_area, pg_col, pg_pd_opt, start = 398)\n",
    "                elif int(p_ed.search(filename.name)[0]) in [41, 42]:\n",
    "                    print('for 41 and 42 tf')\n",
    "                    tf=input_pdf(filename.path, pg_area, pg_col, pg_pd_opt, start = 503)\n",
    "                else:\n",
    "                    tf=input_pdf(filename.path, pg_area, pg_col, pg_pd_opt, start = 407)\n",
    "                    #418, 442\n",
    "                print('in main, looking for pages in : ',filename.path)\n",
    "                drug_pg, otc_pg, dcn_pg, ode_pg, patent_pg, terms_pg = (\n",
    "                    find_dcn_sections(tf[0], opts = 1)\n",
    "                )\n",
    "                print ('Drug List between Pages: {} and {} \\n\\\n",
    "                        Discontinued products between Pages: {} and {} \\n\\\n",
    "                        Patent List between Pages: {} and {}'\\\n",
    "                        .format(drug_pg, otc_pg, dcn_pg, ode_pg, patent_pg, terms_pg)\n",
    "                 )\n",
    "\n",
    "            except Exception as e:\n",
    "                print('File Input error in ',filename, '\\n',e)\n",
    "\n",
    "# Drug Product Parsing Block                \n",
    "            #Note: difference in parsing OB41, P500 (Biologics).  df is seeing an extra line\n",
    "            #Try deleting blank lines.  IF not, hard code the DCN pages...\n",
    "            try:\n",
    "                print('Drug Block')\n",
    "                print('Filename is',filename.name)\n",
    "\n",
    "                if int(p_ed.search(filename.name)[0])<34:\n",
    "                    dpn_pos = 3\n",
    "                    note_pos = 2\n",
    "                    mode = 1\n",
    "                    if int(p_ed.search(filename.name)[0]) == 25:\n",
    "                        df=input_pdf(filename.path, \n",
    "                                     pg_area, \n",
    "                                     dp_col_25, \n",
    "                                     dp_pd_opt_bf34, \n",
    "                                     start = 398)\n",
    "                    elif int(p_ed.search(filename.name)[0]) == 29:\n",
    "                        df=input_pdf(filename.path, \n",
    "                                     pg_area, \n",
    "                                     dp_col_bf34, \n",
    "                                     dp_pd_opt_bf34, \n",
    "                                     start = 398)\n",
    "                    else:\n",
    "                        df=input_pdf(filename.path, \n",
    "                                     pg_area, \n",
    "                                     dp_col_bf34, \n",
    "                                     dp_pd_opt_bf34, \n",
    "                                     start = 407)\n",
    "                else:\n",
    "                    mode = 0\n",
    "                    dpn_pos = 2\n",
    "                    note_pos = 3\n",
    "                    if int(p_ed.search(filename.name)[0]) in [41, 42]:\n",
    "                        print('for 41 and 42 df')\n",
    "                        df=input_pdf(filename.path, \n",
    "                                     pg_area, \n",
    "                                     dp_col_fr34, \n",
    "                                     dp_pd_opt_fr34, \n",
    "                                     start = 503)\n",
    "                    else:\n",
    "                        df=input_pdf(filename.path, \n",
    "                                     pg_area, \n",
    "                                     dp_col_fr34, \n",
    "                                     dp_pd_opt_fr34, \n",
    "                                     start = 407)\n",
    "                \n",
    "                #Remove hidden 'XX' string from pdf\n",
    "                df[0].iloc[:,0].replace('XX',np.nan, inplace = True)\n",
    "                tf[0].iloc[:,0].replace('XX',np.nan, inplace = True)\n",
    "                df[0].dropna(axis = 0, how = 'all', inplace = True)\n",
    "                tf[0].dropna(axis = 0, how = 'all', inplace = True)\n",
    "                df[0].reset_index(drop = True, inplace = True)\n",
    "                tf[0].reset_index(drop = True, inplace = True)\n",
    "                                \n",
    "                prods = parse_dcn(df, tf, dcn_pg, ode_pg, dpn_pos, note_pos, mode)\n",
    "                #prods = parse_dcn(df, tf, 0, ode_pg, dpn_pos, note_pos, mode)\n",
    "                prods['dcn'] = p_yr.search(filename.name)[0]\n",
    "                rn_out_doc = p.sub('_dscn_v2_0.csv', filename.name)\n",
    "                rn_out_doc = otpt_directory+rn_out_doc\n",
    "                prods.to_csv(rn_out_doc)\n",
    "                print('Completed parsing discontinued product info from ',filename.name)\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Drug Product Parse error in ',filename, '\\n',e)     \n",
    "                pd.set_option('display.max_rows', None)    \n",
    "                print(df[0].iloc[drug_pg:(drug_pg+30),:].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b462f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dcn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
